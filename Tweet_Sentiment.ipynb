{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EitanRashkovan/tweet_sentiment/blob/main/Tweet_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnGAew0SYthz",
        "outputId": "0d7d1276-96cb-41ce-fdee-a61c79f4d572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kaggle) (1.26.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->kaggle) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->kaggle) (2.0.12)\n",
            "mkdir: /Users/coltersirlin/.kaggle: File exists\n",
            "cp: kaggle.json: No such file or directory\n",
            "chmod: /Users/coltersirlin/.kaggle/kaggle.json: No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/bin/kaggle\", line 11, in <module>\n",
            "    load_entry_point('kaggle==1.5.12', 'console_scripts', 'kaggle')()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 487, in load_entry_point\n",
            "    return get_distribution(dist).load_entry_point(group, name)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2728, in load_entry_point\n",
            "    return ep.load()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2346, in load\n",
            "    return self.resolve()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2352, in resolve\n",
            "    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /Users/coltersirlin/.kaggle. Or use the environment method.\n",
            "Requirement already satisfied: mglearn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.1.9)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (1.21.0)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (1.0.2)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (1.3.0)\n",
            "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (9.0.1)\n",
            "Requirement already satisfied: cycler in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: imageio in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (2.16.0)\n",
            "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mglearn) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->mglearn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->mglearn) (1.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->mglearn) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->mglearn) (3.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib->mglearn) (4.29.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas->mglearn) (2021.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->mglearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->mglearn) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.12.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c nlp-getting-started\n",
        "!pip install mglearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8fRl7q_cfiJr",
        "outputId": "4cd9d648-8d36-4d40-919e-570e800ff337"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import mglearn\n",
        "\n",
        "trainData = pd.read_csv(\"./train.csv\")\n",
        "testData = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "#looking at data\n",
        "trainData\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j-XRIVJHgoJC",
        "outputId": "6cbc0781-4282-4c19-a455-55b747ab93e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location  \\\n",
              "0         0     NaN      NaN   \n",
              "1         2     NaN      NaN   \n",
              "2         3     NaN      NaN   \n",
              "3         9     NaN      NaN   \n",
              "4        11     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "3258  10861     NaN      NaN   \n",
              "3259  10865     NaN      NaN   \n",
              "3260  10868     NaN      NaN   \n",
              "3261  10874     NaN      NaN   \n",
              "3262  10875     NaN      NaN   \n",
              "\n",
              "                                                   text  \n",
              "0                    Just happened a terrible car crash  \n",
              "1     Heard about #earthquake is different cities, s...  \n",
              "2     there is a forest fire at spot pond, geese are...  \n",
              "3              Apocalypse lighting. #Spokane #wildfires  \n",
              "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
              "...                                                 ...  \n",
              "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
              "3259  Storm in RI worse than last hurricane. My city...  \n",
              "3260  Green Line derailment in Chicago http://t.co/U...  \n",
              "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
              "3262  #CityofCalgary has activated its Municipal Eme...  \n",
              "\n",
              "[3263 rows x 4 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zif8rYsSZsWo",
        "outputId": "2b3dc2b5-feae-42fa-fe72-d69a4b0a929c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keyword              \n",
            "fatalities               45\n",
            "deluge                   42\n",
            "armageddon               42\n",
            "sinking                  41\n",
            "damage                   41\n",
            "                         ..\n",
            "forest%20fire            19\n",
            "epicentre                12\n",
            "threat                   11\n",
            "inundation               10\n",
            "radiation%20emergency     9\n",
            "Length: 221, dtype: int64\n",
            "\n",
            "\n",
            "location      \n",
            "USA               104\n",
            "New York           71\n",
            "United States      50\n",
            "London             45\n",
            "Canada             29\n",
            "                 ... \n",
            "Hueco Mundo         1\n",
            "Hughes, AR          1\n",
            "Huntington, WV      1\n",
            "Huntley, IL         1\n",
            "åø\\_(?)_/åø         1\n",
            "Length: 3341, dtype: int64\n",
            "Number of tweets: \n",
            "id                                                 41429450\n",
            "text      Our Deeds are the Reason of this #earthquake M...\n",
            "target                                                 3271\n",
            "dtype: object\n",
            " Null keywords: \n",
            "61\n",
            " Non-null keywords: \n",
            "7552\n",
            "Null location: \n",
            "2533\n",
            " Non-null location: \n",
            "5080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print(trainData[[\"keyword\"]].value_counts())\n",
        "print(\"\\n\")\n",
        "print(trainData[[\"location\"]].value_counts())\n",
        "\n",
        "#looking at keyword distribution\n",
        "print(\"Number of tweets: \\n{}\\n Null keywords: \\n{}\\n Non-null keywords: \\n{}\".format(trainData.sum(), trainData['keyword'].isna().sum(), trainData['keyword'].notna().sum())) \n",
        "print(\"Null location: \\n{}\\n Non-null location: \\n{}\".format(trainData['location'].isna().sum(), trainData['location'].notna().sum())) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "CI1D9HTTcBG5",
        "outputId": "b6717cf8-feaa-40d4-a84c-80f04bed351f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7613.000000</td>\n",
              "      <td>7613.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5441.934848</td>\n",
              "      <td>0.42966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3137.116090</td>\n",
              "      <td>0.49506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2734.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5408.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8146.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10873.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id      target\n",
              "count   7613.000000  7613.00000\n",
              "mean    5441.934848     0.42966\n",
              "std     3137.116090     0.49506\n",
              "min        1.000000     0.00000\n",
              "25%     2734.000000     0.00000\n",
              "50%     5408.000000     0.00000\n",
              "75%     8146.000000     1.00000\n",
              "max    10873.000000     1.00000"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainData.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSP2wn7xtoFM",
        "outputId": "39ef4bdf-6d91-4f4c-fb7e-dfdad0291151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['no', 'interest', 'afterwards', 'fill', 'is', 'twelve', 'but', 'either', 'might', 'done', 'around', 'besides', 'toward', 'system', 'detail', 'so', 'almost', 'herein', 'down', 'most', 'below', 'has', 'it', 'less', 'they', 'hundred', 'from', 'whereas', 'ours', 'that', 'with', 'had', 'which', 'hers', 'must', 'fifteen', 'something', 'beforehand', 'thereupon', 'someone', 'him', 'can', 'on', 'eg', 'ever', 'until', 'hereby', 'made', 'when', 'and', 'whole', 'well', 'become', 'nowhere', 'very', 'latterly', 'un', 'perhaps', 'what', 'couldnt', 'bill', 'put', 'namely', 'beyond', 'except', 'still', 'you', 'onto', 'ourselves', 'its', 'more', 'cant', 'as', 'whose', 'otherwise', 'whereafter', 'nothing', 'in', 'himself', 'each', 'hence', 'themselves', 'since', 'out', 'find', 'only', 'mine', 'for', 'over', 'thru', 'against', 'own', 'than', 'latter', 'others', 'thence', 'several', 'although', 'thereafter', 'hasnt', 'nevertheless', 'fire', 're', 'his', 'any', 'former', 'first', 'though', 'being', 'fifty', 'via', 'ten', 'if', 'ie', 'wherein', 'anything', 'along', 'again', 'three', 'amount', 'us', 'our', 'up', 'everyone', 'such', 'about', 'enough', 'name', 'some', 'empty', 'keep', 'sometime', 'six', 'of', 'yours', 'wherever', 'anywhere', 'or', 'etc', 'not', 'inc', 'here', 'sometimes', 'i', 'we', 'hereupon', 'else', 'whoever', 'among', 'top', 'your', 'before', 'formerly', 'whether', 'whereby', 'me', 'beside', 'together', 'nobody', 'have', 'yourselves', 'third', 'ltd', 'whither', 'few', 'whenever', 'whereupon', 'became', 'across', 'same', 'hereafter', 'often', 'however', 'two', 'because', 'yet', 'found', 'serious', 'alone', 'every', 'be', 'could', 'further', 'go', 'other', 'thick', 'without', 'where', 'nor', 'show', 'never', 'describe', 'seemed', 'please', 'through', 'amoungst', 'neither', 'under', 'off', 'am', 'behind', 'whatever', 'noone', 'seem', 'too', 'even', 'was', 'into', 'take', 'already', 'part', 'always', 'herself', 'at', 'towards', 'a', 'will', 'side', 'both', 'within', 'then', 'during', 'twenty', 'forty', 'their', 'co', 'now', 'nine', 'between', 'five', 'everywhere', 'get', 'her', 'call', 'also', 'anyway', 'seeming', 'should', 'them', 'many', 'after', 'becoming', 'somewhere', 'upon', 'meanwhile', 'may', 'she', 'while', 'full', 'by', 'thin', 'four', 'everything', 'none', 'somehow', 'once', 'throughout', 'bottom', 'been', 'above', 'con', 'there', 'due', 'how', 'moreover', 'these', 'myself', 'becomes', 'see', 'seems', 'cannot', 'the', 'de', 'next', 'he', 'whence', 'those', 'front', 'give', 'why', 'per', 'back', 'therein', 'therefore', 'cry', 'thus', 'were', 'anyone', 'mill', 'mostly', 'my', 'who', 'much', 'sincere', 'whom', 'are', 'to', 'rather', 'one', 'thereby', 'all', 'itself', 'another', 'indeed', 'last', 'this', 'an', 'least', 'move', 'do', 'would', 'sixty', 'eight', 'eleven', 'anyhow', 'elsewhere', 'amongst', 'yourself', 'make', 'https', 'http']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "stopwords=list(ENGLISH_STOP_WORDS)\n",
        "stopwords.append(\"make\")\n",
        "stopwords.append(\"https\")\n",
        "stopwords.append(\"http\")\n",
        "print(stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CWRPjKPDqoI9",
        "outputId": "c7e3df06-0a73-4d81-ceb6-47b178393a96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'from sklearn.feature_extraction.text import CountVectorizer\\ntweetTrainList = trainData[\"text\"].tolist()\\n\\nvect = CountVectorizer(min_df=15, stop_words=stopwords,  ngram_range=(1,2)).fit(tweetTrainList)\\nX_train = vect.transform(tweetTrainList)\\nprint(\"X_train:\\n{}\".format(repr(X_train)))\\n\\nfeature_names = vect.get_feature_names()\\nprint(\"Number of features: {}\".format(len(feature_names)))\\nprint(\"Every 200th feature: {}\".format(feature_names[::100]))\\n\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from sklearn.feature_extraction.text import CountVectorizer\n",
        "tweetTrainList = trainData[\"text\"].tolist()\n",
        "\n",
        "vect = CountVectorizer(min_df=15, stop_words=stopwords,  ngram_range=(1,2)).fit(tweetTrainList)\n",
        "X_train = vect.transform(tweetTrainList)\n",
        "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
        "\n",
        "feature_names = vect.get_feature_names()\n",
        "print(\"Number of features: {}\".format(len(feature_names)))\n",
        "print(\"Every 200th feature: {}\".format(feature_names[::100]))\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-tH6F9etUK",
        "outputId": "24f1b5c1-72d7-47bf-e522-74067a0e1ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.72\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None, ngram_range=(1,3)), LogisticRegression(max_iter = 10000))\n",
        "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
        "grid.fit(trainData[\"text\"], trainData[\"target\"])\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2iFKZqnrL57",
        "outputId": "a6c2eb6f-6235-4bca-ce69-223ca4f68d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['00' '00 at' '00 pm' ... 'ûïwhen saw coaches' 'ûò' 'ûó']\n",
            "Features with lowest tfidf:\n",
            "['û_ http' 'û_ http co' 'full' 'accident' 'many' 'and the' 'make' 'death'\n",
            " 'help' 'look' 'wildfire' 'right' 'those' 'hot' 'fatal' 'by the'\n",
            " 'northern' 'read' 'god' 'any']\n",
            "Features with highest tfidf: \n",
            "['nc' 'route' 'ar' 'justice' 'al' 'hill' 'check' 'fucking' 'bus' 'his'\n",
            " 'issues' 'same' 'fire' 'lt' 'hey' 'bestnaijamade' 'on fire' 'gt gt' 'gt'\n",
            " 'wreck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
        "# transform the training dataset\n",
        "X_train = vectorizer.transform(trainData[\"text\"])\n",
        "# find maximum value for each of the features over the dataset\n",
        "max_value = X_train.max(axis=0).toarray().ravel()\n",
        "sorted_by_tfidf = max_value.argsort()\n",
        "\n",
        "# get feature names\n",
        "feature_names = np.array(vectorizer.get_feature_names())\n",
        "print(feature_names)\n",
        "print(\"Features with lowest tfidf:\\n{}\".format(\n",
        " feature_names[sorted_by_tfidf[:20]]))\n",
        "print(\"Features with highest tfidf: \\n{}\".format(\n",
        " feature_names[sorted_by_tfidf[-20:]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWySWBK8unhV",
        "outputId": "3cc17b36-a6c3-498e-bffe-7f4091c43ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.00505968 -0.00258535  0.01203631 ...  0.00538484  0.01357392\n",
            "  -0.00443551]]\n",
            "<class 'numpy.ndarray'>\n",
            "6489\n",
            "\n",
            "Lowest tdfif coefficients and words\n",
            "-0.11353188405668546 û_ http\n",
            "-0.0933198677036717 û_ http co\n",
            "-0.0739218716994141 full\n",
            "-0.056244401561052974 accident\n",
            "-0.05500809838514848 many\n",
            "-0.05375693961186721 and the\n",
            "-0.05094881469703667 make\n",
            "-0.046345382919322185 death\n",
            "-0.043767312831582035 help\n",
            "-0.04216588303115151 look\n",
            "-0.040292379736899746 wildfire\n",
            "-0.03896691672028891 right\n",
            "-0.038310742308961386 those\n",
            "-0.03791893486589352 hot\n",
            "-0.037527648579439105 fatal\n",
            "-0.037232126025815916 by the\n",
            "-0.036976532988616445 northern\n",
            "-0.036972252592630546 read\n",
            "-0.03624967789780771 god\n",
            "-0.035588214011523296 any\n",
            "\n",
            "Highest tdfif coefficients and words\n",
            "0.13572348491399858 flood\n",
            "0.10195707205634974 said\n",
            "0.09710852079970905 flames\n",
            "0.09290649740663606 everyone\n",
            "0.09286999782936887 come\n",
            "0.08801229918210726 injured\n",
            "0.07795295641112072 under\n",
            "0.07779661086542639 ever\n",
            "0.07739270350297851 have been\n",
            "0.07615195718944107 while\n",
            "0.07567108879561453 im\n",
            "0.07294490616256237 content\n",
            "0.07200996901046026 cross\n",
            "0.0716938236766313 since\n",
            "0.06709345050638739 most\n",
            "0.06682383088671255 more than\n",
            "0.06598350697133054 military\n",
            "0.06438103221969971 before\n",
            "0.06435066100812985 ass\n",
            "0.06230429404213191 to get\n"
          ]
        }
      ],
      "source": [
        "coeffs = grid.best_estimator_.named_steps[\"logisticregression\"].coef_\n",
        "print(coeffs)\n",
        "coeffList = np.sort(coeffs.squeeze())\n",
        "print(type(coeffList))\n",
        "print(len(feature_names))\n",
        "\n",
        "#lowest tfidf\n",
        "print(\"\\nLowest tdfif coefficients and words\")\n",
        "for i in range(0, 20):\n",
        "  print(str(coeffList[i]) + \" \" + str(feature_names[sorted_by_tfidf[:20]][i]))\n",
        "\n",
        "#highest\n",
        "print(\"\\nHighest tdfif coefficients and words\")\n",
        "\n",
        "for i in range(0, 20):\n",
        "  print(str(coeffList[::-1][i]) + \" \" + str(feature_names[sorted_by_tfidf[20:]][i]))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBDngsWjiBG4",
        "outputId": "6cde49c9-9a38-422a-e72c-6e1159aff0ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6489,)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_names.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "0oc8lwN8dDsA",
        "outputId": "a9d44aac-1191-4e92-c2c5-ccb641919a5a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'mglearn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/p8/8rlylt7140xcbtqrkfb_z4_h0000gn/T/ipykernel_10483/2483703253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmglearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_coefficients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logisticregression\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_top_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mglearn' is not defined"
          ]
        }
      ],
      "source": [
        "mglearn.tools.visualize_coefficients(grid.best_estimator_.named_steps[\"logisticregression\"].coef_, feature_names, n_top_features = 40)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# plot them\n",
        "\n",
        "\n",
        "coef = coeffList.ravel()\n",
        "positive_coefficients = np.argsort(coef)[-20:]\n",
        "negative_coefficients = np.argsort(coef)[:20]\n",
        "interesting_coefficients = np.hstack([negative_coefficients,\n",
        "                                      positive_coefficients])\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "colors = [\"blue\" if c < 0 else \"red\"\n",
        "          for c in coef[interesting_coefficients]]\n",
        "plt.bar(np.arange(2 * 20), coef[interesting_coefficients],\n",
        "        color=colors)\n",
        "\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "plt.xticks(np.arange(1, 1 + 2 * 20),\n",
        "            feature_names, rotation=60,\n",
        "            ha=\"right\")\n",
        "plt.ylabel(\"Coefficient magnitude\")\n",
        "plt.xlabel(\"Feature\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "k6uWiM1-lGTB",
        "outputId": "04a77816-0e75-4c2f-ea6c-889603c3a799"
      },
      "outputs": [],
      "source": [
        "mglearn.tools.visualize_coefficients(grid.best_estimator_.named_steps[\"logisticregression\"].coef_, feature_names, n_top_features = 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqbrJk_jicyb",
        "outputId": "32c937e4-b066-4c08-9cc4-5852848e77de"
      },
      "outputs": [],
      "source": [
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "tQZk2Bu0sgcl",
        "outputId": "a20e29ad-8183-4755-f13b-8ff3ebbb76ac"
      },
      "outputs": [],
      "source": [
        "#Get top and bottom 20 coefficient names (X)\n",
        "#                                  values (Y)\n",
        "feature_values = np.array(vectorizer.g)\n",
        "pltX = feature_names[sorted_by_tfidf[:20]] + feature_names[sorted_by_tfidf[20:]]\n",
        "pltY = \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "p1 = ax.bar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' \n",
        "# Naive Bayes model\n",
        "\n",
        "# store the feature matrix (X) and response vector (y)\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# splitting X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) '''\n",
        "\n",
        "# training the model on training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(trainData[\"text\"], trainData[\"target\"])\n",
        "\n",
        "# making predictions on the testing set\n",
        "y_pred = gnb.predict(testData[\"text\"])\n",
        "\n",
        "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "from sklearn import metrics\n",
        "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(testData[\"target\"], y_pred)*100)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Tweet_Sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
